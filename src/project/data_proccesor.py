# file path: /home/kirill/projects/folium/broker_stand/src/project/data_proccesor.py

from typing import Optional, Dict, Any, List, Tuple
import asyncio
import logging
import os
import math
from datetime import datetime, timedelta

from scipy.signal import find_peaks
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

from queue_manager import QueueManager
from data_source import Message

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DataProcessor:
    def __init__(self, queue_manager: QueueManager):
        self.queue_manager = queue_manager
        # –ò–°–ü–†–ê–í–õ–ï–ù–û: –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –∏–∑ main_pp.py
        self.redis_source_name = "redis_chanel_1per3sec"
        self.kafka_source_name = "kafka_topic_1per0_25sec"
        self._running = False
        self.cleanup_counter = 0
        self.id_loggers: Dict[str, logging.Logger] = {}
        self.frame_counters: Dict[str, int] = {}
        self.id_log_dir = os.path.join("logs", "ids")
        self.windows_dir = os.path.join("logs", "windows")
        os.makedirs(self.id_log_dir, exist_ok=True)
        os.makedirs(self.windows_dir, exist_ok=True)

    def _save_window_visualization(self, kafka_id: str, redis_msg: Message, 
                                   window_data: List[Message], 
                                   peaks_valleys: Dict[str, np.ndarray],
                                   x_data: np.ndarray, y_data: np.ndarray,
                                   timestamps: List[datetime],
                                   best_match: Optional[Tuple[float, Dict[str, Any]]] = None):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –æ–∫–Ω–∞ —Å —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–µ–π –∏ –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –ø–∏–∫–∞–º–∏."""
        try:
            # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ ID
            id_window_dir = os.path.join(self.windows_dir, kafka_id)
            os.makedirs(id_window_dir, exist_ok=True)
            
            # –ü–æ–ª—É—á–∞–µ–º –Ω–æ–º–µ—Ä –∫–∞–¥—Ä–∞
            if kafka_id not in self.frame_counters:
                self.frame_counters[kafka_id] = 0
            frame_num = self.frame_counters[kafka_id]
            self.frame_counters[kafka_id] += 1
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∏–≥—É—Ä—É —Å –æ–¥–Ω–∏–º –≥—Ä–∞—Ñ–∏–∫–æ–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
            fig, ax = plt.subplots(figsize=(12, 10))
            fig.suptitle(f'ID: {kafka_id} | –ö–∞–¥—Ä: {frame_num} | Redis Time: {redis_msg.timestamp.strftime("%H:%M:%S.%f")[:-3]}', 
                        fontsize=14, fontweight='bold')
            
            # –°—Ç—Ä–æ–∏–º —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—é
            ax.plot(x_data, y_data, 'b-', linewidth=2, label='–¢—Ä–∞–µ–∫—Ç–æ—Ä–∏—è Kafka', alpha=0.7, zorder=1)
            
            # –û—Ç–º–µ—á–∞–µ–º –Ω–∞—á–∞–ª–æ –∏ –∫–æ–Ω–µ—Ü —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏
            ax.plot(x_data[0], y_data[0], 'go', markersize=12, label='–ù–∞—á–∞–ª–æ –æ–∫–Ω–∞', zorder=3)
            ax.plot(x_data[-1], y_data[-1], 'ro', markersize=12, label='–ö–æ–Ω–µ—Ü –æ–∫–Ω–∞', zorder=3)
            
            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø–∏–∫–∏ –∏ –≤–ø–∞–¥–∏–Ω—ã
            peak_labels = {
                'peaks_x': ('–ü–∏–∫–∏ X', 'g^'),
                'valleys_x': ('–í–ø–∞–¥–∏–Ω—ã X', 'gv'),
                'peaks_y': ('–ü–∏–∫–∏ Y', 'm^'),
                'valleys_y': ('–í–ø–∞–¥–∏–Ω—ã Y', 'mv')
            }
            
            for peak_type, (label, marker) in peak_labels.items():
                indices = peaks_valleys[peak_type]
                if len(indices) > 0:
                    x_coords = x_data[indices]
                    y_coords = y_data[indices]
                    ax.plot(x_coords, y_coords, marker, markersize=10, 
                           label=label, zorder=4, markeredgecolor='black', markeredgewidth=0.5)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å–∏ –≤—Ä–µ–º–µ–Ω–∏ –¥–ª—è –ø–∏–∫–æ–≤
                    for idx in indices:
                        time_str = timestamps[idx].strftime('%H:%M:%S')
                        ax.annotate(time_str, (x_data[idx], y_data[idx]), 
                                   textcoords="offset points", xytext=(5, 5),
                                   fontsize=7, rotation=45, alpha=0.7)
            
            # –û—Ç–º–µ—á–∞–µ–º –ª—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ, –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ
            if best_match:
                _, best_data = best_match
                best_coord = best_data['point']
                ax.plot(best_coord[0], best_coord[1], 'o', color='gold', markersize=18,
                       label='–õ—É—á—à–µ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ', zorder=6, 
                       markeredgecolor='black', markeredgewidth=2)
            
            ax.set_xlabel('X –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞', fontsize=12)
            ax.set_ylabel('Y –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞', fontsize=12)
            ax.legend(loc='best', fontsize=9)
            ax.grid(True, alpha=0.3)
            ax.set_aspect('equal', adjustable='box')
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–∏
            if best_match:
                distance, best_data = best_match
                info_text = (f"–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ!\n"
                           f"–¢–∏–ø: {best_data['type']}\n"
                           f"–†–∞—Å—Å—Ç–æ—è–Ω–∏–µ: {distance:.2f}–º\n"
                           f"–†–∞–∑–Ω–∏—Ü–∞ –≤—Ä–µ–º–µ–Ω–∏: {best_data['time_diff']:.2f}—Å\n"
                           f"–í—Ä–µ–º—è: {best_data['timestamp'].strftime('%H:%M:%S.%f')[:-3]}")
                fig.text(0.02, 0.02, info_text, fontsize=10, 
                        bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))
            else:
                info_text = (f"–°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ\n"
                           f"–†–∞–∑–º–µ—Ä –æ–∫–Ω–∞: {len(window_data)} —Ç–æ—á–µ–∫\n"
                           f"–ù–∞–π–¥–µ–Ω–æ –ø–∏–∫–æ–≤: {sum(len(v) for v in peaks_valleys.values())}")
                fig.text(0.02, 0.02, info_text, fontsize=10,
                        bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))
            
            plt.tight_layout(rect=[0, 0.08, 1, 0.96])
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            filename = f"frame_{frame_num:04d}.png"
            filepath = os.path.join(id_window_dir, filename)
            plt.savefig(filepath, dpi=100, bbox_inches='tight')
            plt.close(fig)
            
            logger.debug(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è ID {kafka_id}: {filename}")
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ –¥–ª—è ID {kafka_id}: {e}", exc_info=True)

    # --- –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ---
    def _get_id_logger(self, msg_id: str) -> logging.Logger:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –ª–æ–≥–≥–µ—Ä –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ ID."""
        if msg_id not in self.id_loggers:
            id_logger = logging.getLogger(f"id.{msg_id}")
            id_logger.setLevel(logging.INFO)
            id_logger.propagate = False
            
            log_file_path = os.path.join(self.id_log_dir, f"{msg_id}.log")
            file_handler = logging.FileHandler(log_file_path, mode='a', encoding='utf-8')
            formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
            file_handler.setFormatter(formatter)
            
            id_logger.addHandler(file_handler)
            self.id_loggers[msg_id] = id_logger
            logger.info(f"–°–æ–∑–¥–∞–Ω –ª–æ–≥–≥–µ—Ä –¥–ª—è ID: {msg_id}")
        
        return self.id_loggers[msg_id]

    def _log_to_id_file(self, msg_id: str, step: str, data: dict):
        """–õ–æ–≥–∏—Ä—É–µ—Ç —ç—Ç–∞–ø –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤ —Ñ–∞–π–ª, –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–π –ø–æ ID."""
        id_logger = self._get_id_logger(msg_id)
        log_message = f"[STEP: {step}] {data}"
        id_logger.info(log_message)

    def _cleanup_old_kafka_messages(self):
        """
        –£–¥–∞–ª—è–µ—Ç —Å—Ç–∞—Ä—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏–∑ –≤—Å–µ—Ö –æ—á–µ—Ä–µ–¥–µ–π Kafka.
        –£–¥–∞–ª—è—é—Ç—Å—è —Å–æ–æ–±—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Å—Ç–∞—Ä–µ–µ —Å–∞–º–æ–≥–æ —Å—Ç–∞—Ä–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Redis 
        –±–æ–ª–µ–µ —á–µ–º –Ω–∞ cleanup_threshold_seconds —Å–µ–∫—É–Ω–¥.
        """
        try:
            # –ü–æ–ª—É—á–∞–µ–º –æ—á–µ—Ä–µ–¥—å Redis
            redis_queue = self.queue_manager.simple_queues.get(self.redis_source_name)
            if not redis_queue or len(redis_queue) == 0:
                return 0  # –ù–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–π Redis –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–∏
            
            # –ù–∞—Ö–æ–¥–∏–º —Å–∞–º–æ–µ —Å—Ç–∞—Ä–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ Redis
            oldest_redis_msg = redis_queue[0]  # –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –æ—á–µ—Ä–µ–¥–∏ (—Å–∞–º–æ–µ —Å—Ç–∞—Ä–æ–µ)
            cutoff_time = oldest_redis_msg.timestamp - timedelta(seconds=self.cleanup_threshold_seconds)
            
            # –ü–æ–ª—É—á–∞–µ–º —Å–ª–æ–≤–∞—Ä—å –æ—á–µ—Ä–µ–¥–µ–π Kafka
            dict_queues = self.queue_manager.dict_queues.get(self.kafka_source_name, {})
            if not dict_queues:
                return 0
                
            total_removed = 0
            queues_cleaned = 0
            
            # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º –æ—á–µ—Ä–µ–¥—è–º Kafka
            for kafka_id, kafka_queue in dict_queues.items():
                if not kafka_queue:
                    continue
                    
                removed_from_queue = 0
                # –£–¥–∞–ª—è–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å—Ç–∞—Ä—à–µ cutoff_time
                while kafka_queue and kafka_queue[0].timestamp < cutoff_time:
                    kafka_queue.popleft()
                    removed_from_queue += 1
                    
                if removed_from_queue > 0:
                    total_removed += removed_from_queue
                    queues_cleaned += 1
                    
                    # –õ–æ–≥–∏—Ä—É–µ–º –æ—á–∏—Å—Ç–∫—É –¥–ª—è —ç—Ç–æ–≥–æ ID
                    self._log_to_id_file(kafka_id, "periodic_cleanup", {
                        "removed_messages": removed_from_queue,
                        "cutoff_time": str(cutoff_time),
                        "oldest_redis_time": str(oldest_redis_msg.timestamp),
                        "remaining_messages": len(kafka_queue)
                    })
            
            if total_removed > 0:
                logger.info(f"üîÑ –û—á–∏—Å—Ç–∫–∞ Kafka: —É–¥–∞–ª–µ–Ω–æ {total_removed} —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ {queues_cleaned} –æ—á–µ—Ä–µ–¥–µ–π (—Å—Ç–∞—Ä—à–µ {cutoff_time.strftime('%H:%M:%S')})")
            
            return total_removed
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ —Å—Ç–∞—Ä—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π Kafka: {e}", exc_info=True)
            return 0

    async def process_messages(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π."""
        self._running = True
        logger.info(f"–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –∑–∞–ø—É—â–µ–Ω. –û–∂–∏–¥–∞–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏–π –∏–∑ {self.redis_source_name}...")
        # –°—á–µ—Ç—á–∏–∫ –¥–ª—è –ø–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–æ–π –æ—á–∏—Å—Ç–∫–∏
        cleanup_interval = 10  # –í—ã–ø–æ–ª–Ω—è—Ç—å –æ—á–∏—Å—Ç–∫—É –∫–∞–∂–¥—ã–µ 10 –∏—Ç–µ—Ä–∞—Ü–∏–π
        while self._running:
            try:
                redis_queue = self.queue_manager.simple_queues.get(self.redis_source_name)
                
                if not redis_queue or len(redis_queue) == 0:
                    await asyncio.sleep(0.1)
                    continue
                
                # 1. –ë–µ—Ä–µ–º —Å–∞–º–æ–µ —Å—Ç–∞—Ä–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–∑ Redis –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                redis_msg = redis_queue[0]  # –°–º–æ—Ç—Ä–∏–º –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏—è
                
                logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ Redis —Å–æ–æ–±—â–µ–Ω–∏—è: {redis_msg.timestamp}")
                
                # 2. –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –æ—á–µ—Ä–µ–¥–∏ –≤ Kafka
                relevant_queues = self._find_relevant_queues(redis_msg)
                
                if not relevant_queues:
                    logger.debug(f"–î–ª—è —Å–æ–æ–±—â–µ–Ω–∏—è Redis –æ—Ç {redis_msg.timestamp} –Ω–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ—á–µ—Ä–µ–¥–µ–π Kafka. –û–∂–∏–¥–∞–Ω–∏–µ...")
                    await asyncio.sleep(1)
                    continue

                # 3. –ò—â–µ–º –ª—É—á—à–µ–µ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –≤–æ –≤—Å–µ—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ—á–µ—Ä–µ–¥—è—Ö
                best_match = None
                winning_kafka_id = None
                any_peaks_found = False  # –§–ª–∞–≥ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –Ω–∞—Ö–æ–∂–¥–µ–Ω–∏—è —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ–≥–æ –ø–∏–∫–∞

                for kafka_id, kafka_queue in relevant_queues.items():
                    # –õ–æ–≥–∏—Ä—É–µ–º –Ω–∞—á–∞–ª–æ –ø–æ–∏—Å–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ ID
                    self._log_to_id_file(kafka_id, "window_search_start", {
                        "redis_timestamp": str(redis_msg.timestamp),
                        "redis_coord": redis_msg.data.get("coord"),
                        "queue_size": len(kafka_queue)
                    })

                    match_candidate = self._find_best_match_in_window(redis_msg, kafka_queue, kafka_id)
                    
                    if match_candidate:
                        # match_candidate = (distance, best_point_data)
                        distance, best_point_data = match_candidate
                        any_peaks_found = True  # –ù–∞—à–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –ø–∏–∫
                        
                        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —ç—Ç–æ–≥–æ ID
                        self._log_to_id_file(kafka_id, "match_candidate_found", {
                            "distance": distance,
                            "time_diff_sec": best_point_data['time_diff'],
                            "point": best_point_data['point'],
                            "type": best_point_data['type']
                        })
                        
                        if best_match is None or distance < best_match[0]:
                            best_match = match_candidate
                            winning_kafka_id = kafka_id
                    else:
                        # –õ–æ–≥–∏—Ä—É–µ–º, —á—Ç–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ
                        self._log_to_id_file(kafka_id, "no_match_found", {
                            "redis_timestamp": str(redis_msg.timestamp)
                        })
                
                # 4. –ï—Å–ª–∏ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –µ–≥–æ
                if best_match and winning_kafka_id:
                    distance, best_point_data = best_match
                    
                    # –§–∏–Ω–∞–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ–±–µ–¥–∏–≤—à–µ–≥–æ ID
                    final_result = {
                        "status": "matched",
                        "redis": {
                            "timestamp": str(redis_msg.timestamp),
                            "id": redis_msg.id,
                            "coord": redis_msg.data.get("coord"),
                            "new_state": redis_msg.data.get("new_state")
                        },
                        "kafka": {
                            "id": winning_kafka_id, 
                            "point": best_point_data['point'], 
                            "timestamp": str(best_point_data['timestamp']),
                            "type": best_point_data['type'],
                            "section_name": best_point_data.get('section_name')
                        },
                        "metrics": {
                            "time_diff_sec": best_point_data['time_diff'], 
                            "distance": distance
                        }
                    }
                    
                    self._log_to_id_file(winning_kafka_id, "final_result", final_result)
                    logger.info(f"‚úì –ù–∞–π–¥–µ–Ω–æ —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ: Redis({redis_msg.timestamp}) -> Kafka(ID: {winning_kafka_id}, dist: {distance:.2f}m)")

                    # 5. –û—á–∏—Å—Ç–∫–∞ –æ—á–µ—Ä–µ–¥–µ–π
                    redis_queue.popleft()  # –£–¥–∞–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ Redis
                    self._cleanup_kafka_queue(winning_kafka_id, redis_msg.timestamp)
                
                elif not any_peaks_found and relevant_queues:
                    # –ï—Å–ª–∏ –±—ã–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ –æ—á–µ—Ä–µ–¥–∏, –Ω–æ –Ω–∏ –≤ –æ–¥–Ω–æ–π –Ω–µ –Ω–∞—à–ª–∏ –ø–∏–∫–æ–≤ - —É–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ
                    logger.warning(f"‚ö† –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ –ø–∏–∫–∞ –≤–æ –≤—Å–µ—Ö —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ—á–µ—Ä–µ–¥—è—Ö –¥–ª—è Redis({redis_msg.timestamp}). –£–¥–∞–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ.")
                    redis_queue.popleft()  # –£–¥–∞–ª—è–µ–º –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
                    

                self.cleanup_counter += 1
                if self.cleanup_counter >= cleanup_interval:
                    removed_count = self._cleanup_old_kafka_messages()
                    self.cleanup_counter = 0

                await asyncio.sleep(0.01)

            except asyncio.CancelledError:
                logger.info("–ü—Ä–æ—Ü–µ—Å—Å–æ—Ä –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ CancelledError")
                break
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –≤ —Ü–∏–∫–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}", exc_info=True)
                await asyncio.sleep(1)

    def _find_relevant_queues(self, redis_msg: Message) -> Dict[str, 'deque']:
        """
        –≠—Ç–∞–ø 1: –ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ—á–µ—Ä–µ–¥–µ–π.
        –£—Å–ª–æ–≤–∏–µ: —Å–∞–º–æ–µ –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –æ—á–µ—Ä–µ–¥–∏ Kafka –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Å—Ç–∞—Ä—à–µ
        —Å–æ–æ–±—â–µ–Ω–∏—è Redis –∫–∞–∫ –º–∏–Ω–∏–º—É–º –Ω–∞ 3 —Å–µ–∫—É–Ω–¥—ã.
        """
        relevant = {}
        dict_queues = self.queue_manager.dict_queues.get(self.kafka_source_name, {})
        
        if not dict_queues:
            logger.debug(f"–°–ª–æ–≤–∞—Ä—å –æ—á–µ—Ä–µ–¥–µ–π {self.kafka_source_name} –ø—É—Å—Ç –∏–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return relevant
        
        for kafka_id, kafka_queue in dict_queues.items():
            if not kafka_queue:
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É Redis –∏ —Å–∞–º—ã–º –ù–û–í–´–ú —Å–æ–æ–±—â–µ–Ω–∏–µ–º –≤ Kafka
            newest_kafka_msg = kafka_queue[-1]  # –°–∞–º–æ–µ –Ω–æ–≤–æ–µ
            time_diff = (newest_kafka_msg.timestamp - redis_msg.timestamp).total_seconds()
            
            # –õ–æ–≥–∏—Ä—É–µ–º –ø—Ä–æ–≤–µ—Ä–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ ID
            self._log_to_id_file(kafka_id, "relevance_check", {
                "redis_timestamp": str(redis_msg.timestamp),
                "newest_kafka_timestamp": str(newest_kafka_msg.timestamp),
                "time_diff_sec": time_diff,
                "is_relevant": time_diff > 3
            })
            
            if time_diff > 3:
                relevant[kafka_id] = kafka_queue
        
        if relevant:
            logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(relevant)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –æ—á–µ—Ä–µ–¥–µ–π –¥–ª—è Redis({redis_msg.timestamp}): {list(relevant.keys())}")
        
        return relevant

    def _find_best_match_in_window(self, redis_msg: Message, kafka_queue: 'deque', kafka_id: str) -> Optional[Tuple[float, Dict[str, Any]]]:
        """
        –≠—Ç–∞–ø—ã 2 –∏ 3: –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–∫–Ω–∞, –ø–æ–∏—Å–∫ –ø–∏–∫–æ–≤ –∏ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è.
        """
        redis_coord = redis_msg.data.get("coord")
        if not redis_coord or len(redis_coord) != 2:
            self._log_to_id_file(kafka_id, "invalid_redis_coord", {
                "redis_coord": redis_coord
            })
            return None

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–µ –æ–∫–Ω–æ
        window_start = redis_msg.timestamp - timedelta(seconds=10)
        window_end = redis_msg.timestamp + timedelta(seconds=3)

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–∫–Ω–∞
        window_data = [msg for msg in kafka_queue if window_start <= msg.timestamp <= window_end]
        
        if not window_data:
            self._log_to_id_file(kafka_id, "window_formation", {
                "window_start": str(window_start),
                "window_end": str(window_end),
                "window_size": 0,
                "status": "no_data_in_window"
            })
            return None

        # –õ–æ–≥–∏—Ä—É–µ–º —É—Å–ø–µ—à–Ω–æ–µ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–∫–Ω–∞
        self._log_to_id_file(kafka_id, "window_formation", {
            "window_start": str(window_start),
            "window_end": str(window_end),
            "window_size": len(window_data),
            "status": "success"
        })

        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–∏–∫–æ–≤
        coords = [msg.data.get("coord") for msg in window_data if msg.data.get("coord")]
        if len(coords) < 2:  # –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2 —Ç–æ—á–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ –ø–∏–∫–æ–≤
            self._log_to_id_file(kafka_id, "peak_detection", {
                "status": "insufficient_data",
                "coords_count": len(coords)
            })
            return None
            
        x_data = np.array([c[0] for c in coords])
        y_data = np.array([c[1] for c in coords])
        timestamps = [msg.timestamp for msg in window_data if msg.data.get("coord")]
        section_names = [msg.data.get("section_name") for msg in window_data if msg.data.get("coord")]

        # –ü–æ–∏—Å–∫ –ø–∏–∫–æ–≤ –∏ –≤–ø–∞–¥–∏–Ω
        peaks_valleys = self._find_peaks_and_valleys(x_data, y_data)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –ø–∏–∫–æ–≤
        peaks_valleys_counts = {k: len(v) for k, v in peaks_valleys.items()}
        self._log_to_id_file(kafka_id, "peak_detection", {
            "status": "completed",
            "peaks_valleys_counts": peaks_valleys_counts,
            "total_points": sum(peaks_valleys_counts.values())
        })
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –Ω–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–æ—á–∫–∏ (–ø–∏–∫–∏ –∏ –≤–ø–∞–¥–∏–Ω—ã)
        all_points = []
        for type_name, indices in peaks_valleys.items():
            for idx in indices:
                if idx < len(timestamps):
                    point = {
                        "timestamp": timestamps[idx],
                        "coord": coords[idx],
                        "type": type_name,
                        "section_name": section_names[idx] if idx < len(section_names) else None
                    }
                    all_points.append(point)
        
        if not all_points:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –¥–∞–∂–µ –µ—Å–ª–∏ –ø–∏–∫–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã
            self._save_window_visualization(kafka_id, redis_msg, window_data, 
                                           peaks_valleys, x_data, y_data, timestamps, None)
            
            self._log_to_id_file(kafka_id, "filtering_and_matching", {
                "status": "no_peaks_found"
            })
            return None

        # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –ø–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–µ–≥–æ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é
        best_point_data = None
        min_distance = float('inf')
        candidates = []

        for point in all_points:
            time_diff = abs((point['timestamp'] - redis_msg.timestamp).total_seconds())
            dist = math.dist(point['coord'], redis_coord)
            
            candidate_info = {
                "type": point['type'],
                "timestamp": str(point['timestamp']),
                "coord": point['coord'],
                "section_name": point.get('section_name'),
                "time_diff_sec": time_diff,
                "distance": dist,
                "time_filter_passed": time_diff <= 5
            }
            candidates.append(candidate_info)
            
            if time_diff <= 5:
                if dist < min_distance:
                    min_distance = dist
                    best_point_data = {
                        "timestamp": point['timestamp'],
                        "point": point['coord'],
                        "type": point['type'],
                        "time_diff": time_diff,
                        "section_name": point.get('section_name')
                    }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é –æ–∫–Ω–∞ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
        best_match_for_viz = (min_distance, best_point_data) if best_point_data else None
        self._save_window_visualization(kafka_id, redis_msg, window_data, 
                                       peaks_valleys, x_data, y_data, timestamps, best_match_for_viz)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
        self._log_to_id_file(kafka_id, "filtering_and_matching", {
            "total_candidates": len(candidates),
            "candidates": candidates,
            "best_match_found": best_point_data is not None,
            "best_distance": min_distance if best_point_data else None
        })
        
        if best_point_data:
            return (min_distance, best_point_data)
        
        return None

    def _cleanup_kafka_queue(self, kafka_id: str, center_time: datetime):
        """–£–¥–∞–ª—è–µ—Ç –∏–∑ –æ—á–µ—Ä–µ–¥–∏ Kafka –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ —Å—Ç–∞—Ä—à–µ center_time."""
        dict_queues = self.queue_manager.dict_queues.get(self.kafka_source_name, {})
        if kafka_id not in dict_queues:
            return
        
        kafka_queue = dict_queues[kafka_id]
        removed_count = 0
        while kafka_queue and kafka_queue[0].timestamp < center_time:
            kafka_queue.popleft()
            removed_count += 1
        
        if removed_count > 0:
            self._log_to_id_file(kafka_id, "queue_cleanup", {
                "removed_messages": removed_count,
                "center_time": str(center_time),
                "remaining_messages": len(kafka_queue)
            })
            logger.debug(f"–û—á–∏—Å—Ç–∫–∞ –æ—á–µ—Ä–µ–¥–∏ Kafka –¥–ª—è ID {kafka_id}: —É–¥–∞–ª–µ–Ω–æ {removed_count} —Å–æ–æ–±—â–µ–Ω–∏–π.")

    @staticmethod
    def _find_peaks_and_valleys(x_data: np.ndarray, y_data: np.ndarray) -> Dict[str, np.ndarray]:
        """–ù–∞—Ö–æ–¥–∏—Ç –ø–∏–∫–∏ –∏ –≤–ø–∞–¥–∏–Ω—ã –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—è—Ö –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç."""
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–∂–Ω–æ –≤—ã–Ω–µ—Å—Ç–∏ –≤ –∫–æ–Ω—Ñ–∏–≥, –µ—Å–ª–∏ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è
        peaks_x, _ = find_peaks(x_data, height=0.1, distance=100)
        peaks_y, _ = find_peaks(y_data, height=0.1, distance=100)
        valleys_x, _ = find_peaks(-x_data, height=0.1, distance=100)
        valleys_y, _ = find_peaks(-y_data, height=0.1, distance=100)
        
        return {
            'peaks_x': peaks_x,
            'valleys_x': valleys_x,
            'peaks_y': peaks_y,
            'valleys_y': valleys_y
        }

    def stop(self):
        """–û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ—Ç –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä."""
        self._running = False
        logger.info("DataProcessor –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")